{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMe6Q2Vnx6QtsaP7d+n802m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import torch\n","import torch.nn as nn"],"metadata":{"id":"Hanqrogos3VZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_spatial_pos_embedding():\n","\n","    pos_emb_dim = 768\n","\n","    grid_h = torch.arange(3, dtype=torch.float32)\n","    grid_w = torch.arange(3, dtype=torch.float32)\n","    grid = torch.meshgrid(grid_h, grid_w, indexing='ij')\n","    grid = torch.stack(grid, dim=0)\n","\n","    # grid_h_positions -> (Number of patch tokens,)\n","    grid_h_positions = grid[0].reshape(-1)\n","    grid_w_positions = grid[1].reshape(-1)\n","\n","    # Converting to (B, temb_dim / 2)\n","    grid_h_positions = grid_h_positions[:, None].repeat(1, pos_emb_dim // 4)\n","    grid_w_positions = grid_w_positions[:, None].repeat(1, pos_emb_dim // 4)\n","\n","    # factor = 10000^(2i/d_model)\n","    factor = 10000 ** ((torch.arange( start=0, end=pos_emb_dim // 4, dtype=torch.float32) / (pos_emb_dim // 4)))\n","\n","    grid_h_emb = grid_h_positions / factor\n","    grid_w_emb = grid_w_positions / factor\n","\n","    return pos_emb = torch.cat([torch.cat([torch.sin(grid_h_emb), torch.cos(grid_h_emb)], dim=-1), torch.cat([torch.sin(grid_w_emb), torch.cos(grid_w_emb)], dim=-1)], dim=-1)"],"metadata":{"id":"5RdnCJY3tbIU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_temporal_pos_embedding():\n","\n","    temb_dim = 768\n","\n","    # 1D tensor of length batch size\n","    time_steps = torch.arange(28, dtype=torch.float32)\n","\n","    # converting timestepsfrom (B) => (B, 1) => (B, temb_dim / 2)\n","    time_steps = time_steps[:, None].repeat(1, temb_dim // 2)\n","\n","    # factor = 10000^(2i/d_model)\n","    factor = 10000 ** ((torch.arange( start=0, end=temb_dim // 2, dtype=torch.float32) / (temb_dim // 2)) )\n","\n","    # pos / factor\n","    t_emb = time_steps / factor\n","\n","    return torch.cat([torch.sin(t_emb), torch.cos(t_emb)], dim=-1)"],"metadata":{"id":"dTsPUkpMCOfE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class DITVideo(nn.Module):\n","\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, x):\n","\n","        # Shape of x is Batch_size x num_frames x Channels x H x W\n","        B, F, C, H, W = x.shape\n","\n","\n","\n","        '''Patchify'''\n","\n","        # rearrange to (Batch_size * num_frames) x Channels x H x W\n","        x = rearrange(x, 'b f c h w -> (b f) c h w')\n","\n","        # B, C, H, W -> B, Number of Tokens, Patch Dimension || Number of tokens = Patches along height * Patches along width\n","        out = rearrange(x, 'b c (nh patch_height) (nw patch_width) -> b (nh nw) (patch_height patch_width c)', patch_height=2, patch_width=2)\n","\n","        out = nn.Linear(2*2*3, 768)(out)\n","\n","        # out->(Batch_size * num_frames) x num_patch_tokens x hidden_size\n","        num_patch_tokens = out.shape[1]\n","\n","\n","\n","        '''First BLock'''\n","        # spatial layer\n","        out = nn.TransformerEncoderLayer(d_model=768, nhead=12, dim_feedforward=4 * 768)(out + get_spatial_pos_embedding()) # dim => (Batch_size * num_frames) x num_patch_tokens x hidden_size\n","\n","        # rearranging for temporal layer\n","        out = rearrange(out, '(b f) p d -> (b p) f d', b=B) # dim => (B * patch_tokens) x num_frames x hidden_size\n","\n","        # temporal layer\n","        out = nn.TransformerEncoderLayer( d_model=768, nhead=12, dim_feedforward=4 * 768)(out + get_temporal_pos_embedding())\n","\n","\n","\n","\n","        '''Second Block'''\n","\n","        # 2.a. spatial transformer\n","        out = rearrange(out, '(b p) f d -> (b f) p d',f=self.num_frames, p=num_patch_tokens) # Rearrange to (B * num_frames) x num_patch_tokens x hidden_size\n","        out = nn.TransformerEncoderLayer( d_model=768, nhead=12, dim_feedforward=4 * 768)(out)\n","\n","        # 2.b. temporal transformer\n","        out = rearrange(out, '(b f) p d -> (b p) f d', b=B)\n","        out = nn.TransformerEncoderLayer( d_model=768, nhead=12, dim_feedforward=4 * 768)(out)\n","\n","\n","\n","        '''Third Block'''\n","\n","        # 3.a. spatial transformer\n","        out = rearrange(out, '(b p) f d -> (b f) p d',f=self.num_frames, p=num_patch_tokens)\n","        out = nn.TransformerEncoderLayer( d_model=768, nhead=12, dim_feedforward=4 * 768)(out)\n","\n","        # 3.b. temporal transformer\n","        out = rearrange(out, '(b f) p d -> (b p) f d', b=B)\n","        out = nn.TransformerEncoderLayer( d_model=768, nhead=12, dim_feedforward=4 * 768)(out)\n","\n","\n","\n","\n","        ''' Rearranging back ''''\n","        out = rearrange(out, '(b p) f d -> (b f) p d',f=28, p=num_patch_tokens)\n","\n","\n","\n","        ''' Unpatchify '''\n","        # (Batch_size * num_frames) x patches x hidden_size =>> (B * num_frames) x patches x (patch height*patch width*channels)\n","        out = nn.Linear(768, 2 * 2 * 3)(out)\n","        out = rearrange(out, 'b (nh nw) (ph pw c) -> b c (nh ph) (nw pw)', ph=2, pw=2, nw=3, nh=3)\n","\n","\n","        # out -> (Batch_size * num_frames) x channels x h x w\n","        out = out.reshape((B, F, C, H, W))\n","        return out"],"metadata":{"id":"P6zwgiintUrl"},"execution_count":null,"outputs":[]}]}