{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here I am just coding the model, you can copy the other modules like dataset creation and training from the 3dCNN code [here](https://github.com/khetansarvesh/video/blob/main/action_recognision/3DCNN.ipynb)!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yck-33e4nsZd"
      },
      "outputs": [],
      "source": [
        "class Resnet_LSTM_Model(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Resnet_LSTM_Model, self).__init__()\n",
        "\n",
        "        # ResNet\n",
        "        resnet = models.resnet152(pretrained=True)\n",
        "        modules = list(resnet.children())[:-1]      # delete the last fc layer of resent architecture\n",
        "        self.resnet = nn.Sequential(*modules)\n",
        "\n",
        "        # FFNN\n",
        "        self.ffn1 = nn.Sequential(\n",
        "                                    nn.Linear(resnet.fc.in_features, 1024), nn.BatchNorm1d(1024, momentum=0.01), nn.ReLU(),\n",
        "                                    nn.Linear(1024, 768), nn.BatchNorm1d(768, momentum=0.01), nn.ReLU(),\n",
        "                                    nn.dropout(0.3),\n",
        "                                    nn.Linear(768, 512)\n",
        "                                )\n",
        "\n",
        "        self.LSTM = nn.LSTM( input_size=512, hidden_size=512, num_layers=3, batch_first=True)\n",
        "\n",
        "\n",
        "        self.ffn2 = nn.Sequential(\n",
        "                                  nn.Linear(512, 256), nn.ReLU(),\n",
        "                                  nn.Linear(256, 101)\n",
        "                                  )\n",
        "\n",
        "\n",
        "    def forward(self, x_3d):\n",
        "\n",
        "        cnn_embed_seq = []\n",
        "        for t in range(x_3d.size(1)):\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                # Resnet\n",
        "                x = self.resnet(x_3d[:, t, :, :, :])\n",
        "\n",
        "                # Flatten\n",
        "                x = x.view(x.size(0), -1)\n",
        "\n",
        "            # FFNN\n",
        "            x = self.ffn1(x)\n",
        "            cnn_embed_seq.append(x)\n",
        "\n",
        "        # swap time and sample dim such that (sample dim, time dim, CNN latent dim)\n",
        "        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=0).transpose_(0, 1) # shape => (batch, time_step, input_size)\n",
        "\n",
        "        # passing through LSTM Layer\n",
        "        self.LSTM.flatten_parameters()\n",
        "        lstm_output, (h_n, h_c) = self.LSTM(cnn_embed_seq, None)  # shape_lstm_output => (batch, time_step, output_size), shape_h_n => (n_layers, batch, hidden_size), shape_h_c => (n_layers, batch, hidden_size)\n",
        "\n",
        "        # passing through FFNN Layer\n",
        "        final_output = self.fnn2(lstm_output[:, -1, :])   # choose x at the last time step\n",
        "\n",
        "        return final_output"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
