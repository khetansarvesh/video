{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Here I am just coding the model, you can copy the other modules like dataset creation and training from the 3dCNN code [here](https://github.com/khetansarvesh/video/blob/main/action_recognision/3DCNN.ipynb)!!"
      ],
      "metadata": {
        "id": "IhDRCmOIc9Fh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_RNN_Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN_RNN_Model, self).__init__()\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "                                    nn.Conv2d(3, 32, kernel_size=5, stride=2, padding=0), nn.BatchNorm2d(32, momentum=0.01),nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=0), nn.BatchNorm2d(64, momentum=0.01), nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=0), nn.BatchNorm2d(128, momentum=0.01), nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=0), nn.BatchNorm2d(256, momentum=0.01), nn.ReLU(inplace=True),\n",
        "                                )\n",
        "\n",
        "\n",
        "        self.conv1_outshape = conv2D_output_size((256, 342), (0,0), (5,5), (2,2))\n",
        "        self.conv2_outshape = conv2D_output_size(self.conv1_outshape, (0,0), (3,3), (2,2))\n",
        "        self.conv3_outshape = conv2D_output_size(self.conv2_outshape, (0,0), (3,3), (2,2))\n",
        "        self.conv4_outshape = conv2D_output_size(self.conv3_outshape, (0,0), (3,3), (2,2))\n",
        "\n",
        "        self.fnn1 = nn.Sequential(\n",
        "                                      nn.Linear(256 * self.conv4_outshape[0] * self.conv4_outshape[1], 1024), nn.ReLU(),\n",
        "                                      nn.Linear(1024, 768), nn.ReLU(),\n",
        "                                      nn.Dropout(0.3),\n",
        "                                      nn.Linear(768, 101)\n",
        "                                  )\n",
        "\n",
        "\n",
        "        self.LSTM = nn.LSTM( input_size=512, hidden_size=512, num_layers=3, batch_first=True)\n",
        "\n",
        "\n",
        "        self.ffn2 = nn.Sequential(\n",
        "                                  nn.Linear(512, 256), nn.ReLU(),\n",
        "                                  nn.Linear(256, 101)\n",
        "                                  )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x_3d):\n",
        "        cnn_embed_seq = []\n",
        "\n",
        "        # iterating over each frame in the video\n",
        "        for t in range(x_3d.size(1)):\n",
        "\n",
        "            # CNNs\n",
        "            x = self.conv(x_3d[:, t, :, :, :])\n",
        "\n",
        "            # Flattening\n",
        "            x = x.view(x.size(0), -1)\n",
        "\n",
        "            # FC layers\n",
        "            x = self.fnn1(x)\n",
        "            cnn_embed_seq.append(x)\n",
        "\n",
        "        # swap time and sample dim such that (sample dim, time dim, CNN latent dim)\n",
        "        cnn_embed_seq = torch.stack(cnn_embed_seq, dim=0).transpose_(0, 1) # shape => (batch, time_step, input_size)\n",
        "\n",
        "        # passing through LSTM Layer\n",
        "        self.LSTM.flatten_parameters()\n",
        "        lstm_output, (h_n, h_c) = self.LSTM(cnn_embed_seq, None)  # shape_lstm_output => (batch, time_step, output_size), shape_h_n => (n_layers, batch, hidden_size), shape_h_c => (n_layers, batch, hidden_size)\n",
        "\n",
        "        # passing through FFNN Layer\n",
        "        final_output = self.fnn2(lstm_output[:, -1, :])   # choose x at the last time step\n",
        "\n",
        "        return final_output\n"
      ],
      "metadata": {
        "id": "i4OmkDGWGZt2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}